{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links to shared data MovieLens\n",
    "# source on kaggle: https://www.kaggle.com/code/quangnhatbui/movie-recommender/data\n",
    "MOVIES_METADATA_URL = 'https://drive.google.com/file/d/19g6-apYbZb5D-wRj4L7aYKhxS-fDM4Fb/view?usp=share_link'\n",
    "RATINGS_SMALL_URL = 'https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nikitasenyatkin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from ast import literal_eval\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# download stop words beforehand\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Helper functions to avoid copypaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_gdrive(url):\n",
    "    \"\"\"\n",
    "    gets csv data from a given url (taken from file -> share -> copy link)\n",
    "    :url: example https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link\n",
    "    \"\"\"\n",
    "    file_id = url.split('/')[-2]\n",
    "    file_path = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init lemmatizer to avoid slow performance\n",
    "mystem = Mystem() \n",
    "\n",
    "def word_tokenize_clean(doc: str, stop_words: list):\n",
    "    '''\n",
    "    tokenize from string to list of words\n",
    "    '''\n",
    "\n",
    "    # split into lower case word tokens \\w lemmatization\n",
    "    tokens = list(set(mystem.lemmatize(doc.lower())))\n",
    "  \n",
    "    # remove tokens that are not alphabetic (including punctuation) and not a stop word\n",
    "    tokens = [word for word in tokens if word.isalpha() and not word in stop_words \\\n",
    "              not in list(punctuation)]\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "\n",
       "     original_title                                           overview  ...  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "2  Grumpier Old Men  A family wedding reignites the ancient feud be...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "2   1995-12-22          0.0   101.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline             title  video  \\\n",
       "0                                                NaN         Toy Story  False   \n",
       "1          Roll the dice and unleash the excitement!           Jumanji  False   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...  Grumpier Old Men  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          7.7     5415.0  \n",
       "1          6.9     2413.0  \n",
       "2          6.5       92.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv information about films etc\n",
    "movies_metadata = read_csv_from_gdrive(MOVIES_METADATA_URL)\n",
    "movies_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what columns we have\n",
    "movies_metadata.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get accurate results we need to preprocess text a bit. The pipeline will be as follows:\n",
    "\n",
    "- Filter only necessary columns from movies_metadada : id, original_title, overview;\n",
    "- Define `model_index` for model to match back with `id` column;\n",
    "- Text cleaning: removing stopwords & punctuation, lemmatization for further tokenization and tagged document creatin required for gensim.Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              45466 non-null  object\n",
      " 1   original_title  45466 non-null  object\n",
      " 2   overview        44512 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# filter cols\n",
    "sample = movies_metadata[['id', 'original_title', 'overview']].copy()\n",
    "sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "original_title    0\n",
       "overview          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you see from above, we have missing overview in some cases -- let's fill it with the original title\n",
    "sample.loc[sample['overview'].isnull(), 'overview'] = sample.loc[sample['overview'].isnull(), 'original_title']\n",
    "sample.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model_index and make it as string\n",
    "sample = sample.reset_index().rename(columns = {'index': 'model_index'})\n",
    "sample['model_index'] = sample['model_index'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapper with title and model_idnex to use it further in evaluation\n",
    "movies_inv_mapper = dict(zip(sample['original_title'].str.lower(), sample['model_index'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['put',\n",
       "  'scene',\n",
       "  'andy',\n",
       "  'separate',\n",
       "  'onto',\n",
       "  'circumstances',\n",
       "  'brings',\n",
       "  'lightyear',\n",
       "  'place',\n",
       "  'heart',\n",
       "  'buzz',\n",
       "  'toys',\n",
       "  'owner',\n",
       "  'afraid',\n",
       "  'aside',\n",
       "  'learns',\n",
       "  'happily',\n",
       "  'birthday',\n",
       "  'room',\n",
       "  'woody',\n",
       "  'differences',\n",
       "  'plots',\n",
       "  'live',\n",
       "  'losing',\n",
       "  'eventually',\n",
       "  'led',\n",
       "  'duo'],\n",
       " ['world',\n",
       "  'magical',\n",
       "  'invite',\n",
       "  'hope',\n",
       "  'rhinoceroses',\n",
       "  'monkeys',\n",
       "  'enchanted',\n",
       "  'creatures',\n",
       "  'finish',\n",
       "  'living',\n",
       "  'three',\n",
       "  'unwittingly',\n",
       "  'alan',\n",
       "  'game',\n",
       "  'door',\n",
       "  'years',\n",
       "  'giant',\n",
       "  'freedom',\n",
       "  'running',\n",
       "  'adult',\n",
       "  'peter',\n",
       "  'trapped',\n",
       "  'room',\n",
       "  'siblings',\n",
       "  'terrifying',\n",
       "  'proves',\n",
       "  'discover',\n",
       "  'judy',\n",
       "  'risky',\n",
       "  'board',\n",
       "  'opens',\n",
       "  'evil',\n",
       "  'find',\n",
       "  'inside'],\n",
       " ['family',\n",
       "  'fish',\n",
       "  'interested',\n",
       "  'alarming',\n",
       "  'restaurant',\n",
       "  'scare',\n",
       "  'away',\n",
       "  'reignites',\n",
       "  'time',\n",
       "  'locals',\n",
       "  'door',\n",
       "  'meanwhile',\n",
       "  'feud',\n",
       "  'shop',\n",
       "  'hot',\n",
       "  'next',\n",
       "  'local',\n",
       "  'max',\n",
       "  'ancient',\n",
       "  'john',\n",
       "  'bait',\n",
       "  'sultry',\n",
       "  'neighbors',\n",
       "  'cooking',\n",
       "  'italian',\n",
       "  'opens',\n",
       "  'worry',\n",
       "  'seafood',\n",
       "  'divorcée',\n",
       "  'wedding',\n",
       "  'less',\n",
       "  'buddies',\n",
       "  'fishing'],\n",
       " ['friends',\n",
       "  'holding',\n",
       "  'elusive',\n",
       "  'man',\n",
       "  'stellar',\n",
       "  'bernie',\n",
       "  'talk',\n",
       "  'glo',\n",
       "  'breath',\n",
       "  'break',\n",
       "  'confidants',\n",
       "  'determined',\n",
       "  'lovers',\n",
       "  'cheated',\n",
       "  'stepped',\n",
       "  'way',\n",
       "  'robin',\n",
       "  'better',\n",
       "  'good',\n",
       "  'women',\n",
       "  'find',\n",
       "  'breathe',\n",
       "  'mistreated',\n",
       "  'string',\n",
       "  'less',\n",
       "  'vannah',\n",
       "  'waiting'],\n",
       " ['selling',\n",
       "  'kid',\n",
       "  'grandchild',\n",
       "  'planning',\n",
       "  'recovered',\n",
       "  'banks',\n",
       "  'wife',\n",
       "  'nina',\n",
       "  'plan',\n",
       "  'daughter',\n",
       "  'arrival',\n",
       "  'change',\n",
       "  'expecting',\n",
       "  'home',\n",
       "  'receives',\n",
       "  'like',\n",
       "  'wedding',\n",
       "  'news',\n",
       "  'pregnant',\n",
       "  'george'],\n",
       " ['detective',\n",
       "  'mentally',\n",
       "  'master',\n",
       "  'ability',\n",
       "  'mouse',\n",
       "  'top',\n",
       "  'unstable',\n",
       "  'man',\n",
       "  'angeles',\n",
       "  'without',\n",
       "  'violence',\n",
       "  'dedication',\n",
       "  'insane',\n",
       "  'respects',\n",
       "  'game',\n",
       "  'cat',\n",
       "  'vincent',\n",
       "  'even',\n",
       "  'may',\n",
       "  'rest',\n",
       "  'obsessive',\n",
       "  'various',\n",
       "  'pursues',\n",
       "  'notch',\n",
       "  'neil',\n",
       "  'hanna',\n",
       "  'crew',\n",
       "  'thief',\n",
       "  'though',\n",
       "  'mccauley',\n",
       "  'end',\n",
       "  'heists',\n",
       "  'leads',\n",
       "  'aware',\n",
       "  'recognizes',\n",
       "  'throughout',\n",
       "  'los'],\n",
       " ['brother',\n",
       "  'ugly',\n",
       "  'focused',\n",
       "  'duckling',\n",
       "  'something',\n",
       "  'business',\n",
       "  'remarkable',\n",
       "  'carefree',\n",
       "  'say',\n",
       "  'change',\n",
       "  'crush',\n",
       "  'still',\n",
       "  'feelings',\n",
       "  'harbors',\n",
       "  'playboy',\n",
       "  'undergone'],\n",
       " ['family',\n",
       "  'friends',\n",
       "  'town',\n",
       "  'deadly',\n",
       "  'choose',\n",
       "  'evidence',\n",
       "  'accused',\n",
       "  'huck',\n",
       "  'trying',\n",
       "  'sawyer',\n",
       "  'several',\n",
       "  'finn',\n",
       "  'tom',\n",
       "  'witnesses',\n",
       "  'go',\n",
       "  'friendship',\n",
       "  'honoring',\n",
       "  'retrieve',\n",
       "  'adventures',\n",
       "  'becomes',\n",
       "  'huckleberry',\n",
       "  'murder',\n",
       "  'alcoholic',\n",
       "  'young',\n",
       "  'boy',\n",
       "  'oath',\n",
       "  'mischievous',\n",
       "  'injun',\n",
       "  'future',\n",
       "  'joe'],\n",
       " ['father',\n",
       "  'suddenly',\n",
       "  'boothe',\n",
       "  'suspense',\n",
       "  'demanding',\n",
       "  'dollars',\n",
       "  'abort',\n",
       "  'superstar',\n",
       "  'cup',\n",
       "  'portrays',\n",
       "  'van',\n",
       "  'whose',\n",
       "  'action',\n",
       "  'drop',\n",
       "  'championship',\n",
       "  'powers',\n",
       "  'buzzer',\n",
       "  'captors',\n",
       "  'game',\n",
       "  'packed',\n",
       "  'billion',\n",
       "  'back',\n",
       "  'sets',\n",
       "  'rescue',\n",
       "  'taken',\n",
       "  'set',\n",
       "  'stanley',\n",
       "  'plan',\n",
       "  'daughter',\n",
       "  'final',\n",
       "  'international',\n",
       "  'thriller',\n",
       "  'explosion',\n",
       "  'hockey',\n",
       "  'tension',\n",
       "  'claude',\n",
       "  'teams',\n",
       "  'end',\n",
       "  'frantically',\n",
       "  'damme',\n",
       "  'impending',\n",
       "  'jean',\n",
       "  'motion'],\n",
       " ['unmask',\n",
       "  'janus',\n",
       "  'prevent',\n",
       "  'leader',\n",
       "  'britain',\n",
       "  'head',\n",
       "  'goldeneye',\n",
       "  'utilizing',\n",
       "  'inflict',\n",
       "  'mysterious',\n",
       "  'james',\n",
       "  'weapons',\n",
       "  'system',\n",
       "  'devastating',\n",
       "  'must',\n",
       "  'revenge',\n",
       "  'syndicate',\n",
       "  'bond'],\n",
       " ['world',\n",
       "  'men',\n",
       "  'wants',\n",
       "  'ratings',\n",
       "  'anything',\n",
       "  'u',\n",
       "  'washington',\n",
       "  'spark',\n",
       "  'approval',\n",
       "  'powerful',\n",
       "  'decimate',\n",
       "  'widowed',\n",
       "  'president',\n",
       "  'covets',\n",
       "  'wild',\n",
       "  'lobbyist',\n",
       "  'wade',\n",
       "  'courting',\n",
       "  'rumors',\n",
       "  'sydney',\n",
       "  'attempts',\n",
       "  'andrew',\n",
       "  'one',\n",
       "  'ellen',\n",
       "  'shepherd'],\n",
       " ['fresh',\n",
       "  'able',\n",
       "  'charms',\n",
       "  'doorstep',\n",
       "  'dr',\n",
       "  'falls',\n",
       "  'vampire',\n",
       "  'count',\n",
       "  'van',\n",
       "  'helsing',\n",
       "  'may',\n",
       "  'vanquish',\n",
       "  'lawyer',\n",
       "  'prey',\n",
       "  'joins',\n",
       "  'blood',\n",
       "  'enter',\n",
       "  'shows',\n",
       "  'search',\n",
       "  'one'],\n",
       " ['deadly',\n",
       "  'life',\n",
       "  'prevent',\n",
       "  'risks',\n",
       "  'nome',\n",
       "  'wolf',\n",
       "  'ravaging',\n",
       "  'alaska',\n",
       "  'outcast',\n",
       "  'epidemic',\n",
       "  'half'],\n",
       " ['world',\n",
       "  'self',\n",
       "  'scandal',\n",
       "  'american',\n",
       "  'man',\n",
       "  'fate',\n",
       "  'spanning',\n",
       "  'would',\n",
       "  'california',\n",
       "  'powers',\n",
       "  'destructive',\n",
       "  'epic',\n",
       "  'richard',\n",
       "  'presidency',\n",
       "  'president',\n",
       "  'look',\n",
       "  'star',\n",
       "  'boyhood',\n",
       "  'carrying',\n",
       "  'shoulders',\n",
       "  'troubled',\n",
       "  'battling',\n",
       "  'demands',\n",
       "  'within',\n",
       "  'nixon',\n",
       "  'shocking',\n",
       "  'watergate',\n",
       "  'end',\n",
       "  'cast'],\n",
       " ['shaw',\n",
       "  'dawg',\n",
       "  'morgan',\n",
       "  'unfortunately',\n",
       "  'uncle',\n",
       "  'mutiny',\n",
       "  'crown',\n",
       "  'held',\n",
       "  'difficult',\n",
       "  'three',\n",
       "  'map',\n",
       "  'portion',\n",
       "  'pirate',\n",
       "  'raids',\n",
       "  'william',\n",
       "  'treasure',\n",
       "  'murderous',\n",
       "  'recover',\n",
       "  'abilities',\n",
       "  'leadership',\n",
       "  'quest',\n",
       "  'final',\n",
       "  'skeptical',\n",
       "  'adams',\n",
       "  'british',\n",
       "  'must',\n",
       "  'complete',\n",
       "  'portions',\n",
       "  'made',\n",
       "  'efforts',\n",
       "  'crew',\n",
       "  'yet',\n",
       "  'slave',\n",
       "  'end'],\n",
       " ['underbelly',\n",
       "  'mafia',\n",
       "  'life',\n",
       "  'vegas',\n",
       "  'las',\n",
       "  'dark',\n",
       "  'paradise',\n",
       "  'gambling'],\n",
       " ['inheritance',\n",
       "  'opposites',\n",
       "  'dies',\n",
       "  'titular',\n",
       "  'leaving',\n",
       "  'rich',\n",
       "  'wife',\n",
       "  'two',\n",
       "  'poor',\n",
       "  'second',\n",
       "  'dashwood',\n",
       "  'mr',\n",
       "  'rules',\n",
       "  'daughters'],\n",
       " ['hotel',\n",
       "  'another',\n",
       "  'ted',\n",
       "  'place',\n",
       "  'guests',\n",
       "  'service',\n",
       "  'evening',\n",
       "  'night',\n",
       "  'outrageous',\n",
       "  'first',\n",
       "  'happening',\n",
       "  'serving',\n",
       "  'bellhop',\n",
       "  'room',\n",
       "  'job',\n",
       "  'unbelievable',\n",
       "  'predicaments',\n",
       "  'unusual',\n",
       "  'seems',\n",
       "  'one'],\n",
       " ['tribal',\n",
       "  'missing',\n",
       "  'sacred',\n",
       "  'vicious',\n",
       "  'journey',\n",
       "  'accomplish',\n",
       "  'friendly',\n",
       "  'war',\n",
       "  'result',\n",
       "  'fails',\n",
       "  'summoned',\n",
       "  'shikaka',\n",
       "  'africa',\n",
       "  'finds',\n",
       "  'tribe',\n",
       "  'ashram',\n",
       "  'warrior',\n",
       "  'must',\n",
       "  'princess',\n",
       "  'tibet',\n",
       "  'jungles',\n",
       "  'find',\n",
       "  'wedding',\n",
       "  'wachootoos',\n",
       "  'perilous',\n",
       "  'animal',\n",
       "  'prince',\n",
       "  'wachati',\n",
       "  'ace'],\n",
       " ['cop',\n",
       "  'york',\n",
       "  'fellow',\n",
       "  'foster',\n",
       "  'brother',\n",
       "  'trainload',\n",
       "  'fares',\n",
       "  'transit',\n",
       "  'protect',\n",
       "  'decides',\n",
       "  'new',\n",
       "  'vengeful',\n",
       "  'steal',\n",
       "  'tries',\n",
       "  'subway']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess by removing non-character data, stopwords\n",
    "tags_corpus = sample['overview'].values\n",
    "tags_corpus = [re.sub('-[!/()0-9]', '', x) for x in tags_corpus]\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "tags_doc = [word_tokenize_clean(description, stop_words) for description in tags_corpus]\n",
    "tags_doc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data as model input for Word2Vec\n",
    "## it takes some time to execute\n",
    "tags_doc = [TaggedDocument(words = word_tokenize_clean(D, stop_words), tags = [str(i)]) for i, D in enumerate(tags_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['world', 'magical', 'invite', 'hope', 'rhinoceroses', 'monkeys', 'enchanted', 'creatures', 'finish', 'living', 'three', 'unwittingly', 'alan', 'game', 'door', 'years', 'giant', 'freedom', 'running', 'adult', 'peter', 'trapped', 'room', 'siblings', 'terrifying', 'proves', 'discover', 'judy', 'risky', 'board', 'opens', 'evil', 'find', 'inside'], tags=['1'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check what do we have\n",
    "## tag = movie index\n",
    "tags_doc[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_SIZE = 50\n",
    "ALPHA = .02\n",
    "MIN_ALPHA = .00025\n",
    "MIN_COUNT = 5\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "model = Doc2Vec(vector_size = VEC_SIZE,\n",
    "                alpha = ALPHA, \n",
    "                min_alpha = MIN_ALPHA,\n",
    "                min_count = MIN_COUNT,\n",
    "                dm = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vocab from all tag docs\n",
    "model.build_vocab(tags_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.train(tags_doc,\n",
    "            total_examples = model.corpus_count,\n",
    "            epochs = EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Evaluate the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we watched movie `batman` and based on that generate recommendation similar to it's description.\n",
    "\n",
    "To do that we need\n",
    "- To extract movie id from `movies_inv_mapper` we created to map back titles from model output\n",
    "- Load embeddings from trained model\n",
    "- Use built-in most_similar() method to get most relevant recommendations based on film embedding\n",
    "- Finally, map title names for sense-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8603"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get id\n",
    "movie_id = movies_inv_mapper['batman']\n",
    "movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained embeddings \n",
    "movies_vectors = model.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings = movies_vectors[movie_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.0160208e-02, -1.8253161e-01,  2.7860367e-01, -1.9340388e-02,\n",
       "       -2.6517289e-02,  1.8640238e-01, -3.3289498e-01, -6.1052497e-02,\n",
       "       -3.5598734e-01, -3.8000790e-04, -1.7075939e-01, -1.1591378e-01,\n",
       "        7.9556266e-05, -2.0348647e-01,  2.0137224e-01, -9.6725069e-02,\n",
       "        2.0268382e-01, -1.6914688e-01,  1.5876643e-01, -2.0017324e-01,\n",
       "        9.4643004e-02,  1.4631657e-01, -3.1319104e-02,  1.7299244e-01,\n",
       "        1.5535557e-01,  2.1169420e-01, -1.1648132e-01, -1.2777744e-01,\n",
       "        3.0593607e-01, -2.5232095e-01,  2.5669878e-02,  6.3207977e-02,\n",
       "       -4.3362007e-02,  7.3174194e-02, -3.5317650e-01,  2.9851297e-01,\n",
       "       -1.5897123e-02, -7.3791169e-02,  1.8562043e-01,  2.0299160e-01,\n",
       "        1.6092224e-01, -2.9811222e-02, -3.5844274e-02,  1.4017850e-01,\n",
       "        1.3455860e-02, -3.6246192e-01,  6.1877277e-02,  2.6866566e-02,\n",
       "       -1.2715700e-01,  4.0484986e-01], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_index</th>\n",
       "      <th>model_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5713</td>\n",
       "      <td>0.959517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19227</td>\n",
       "      <td>0.958552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43461</td>\n",
       "      <td>0.953251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13835</td>\n",
       "      <td>0.952664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_index  model_score\n",
       "0        8603     1.000000\n",
       "1        5713     0.959517\n",
       "2       19227     0.958552\n",
       "3       43461     0.953251\n",
       "4       13835     0.952664"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get recommendations\n",
    "similars = model.docvecs.most_similar(positive = [movie_embeddings], topn = 20)\n",
    "output = pd.DataFrame(similars, columns = ['model_index', 'model_score'])\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse values and indices to map names in dataframe\n",
    "name_mapper = {v: k for k, v in movies_inv_mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_index</th>\n",
       "      <th>model_score</th>\n",
       "      <th>title_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>batman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5713</td>\n",
       "      <td>0.959517</td>\n",
       "      <td>rollover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19227</td>\n",
       "      <td>0.958552</td>\n",
       "      <td>carbon nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43461</td>\n",
       "      <td>0.953251</td>\n",
       "      <td>megafault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13835</td>\n",
       "      <td>0.952664</td>\n",
       "      <td>k2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6816</td>\n",
       "      <td>0.952464</td>\n",
       "      <td>death machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43165</td>\n",
       "      <td>0.950795</td>\n",
       "      <td>the zookeeper's wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7772</td>\n",
       "      <td>0.950565</td>\n",
       "      <td>this island earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10227</td>\n",
       "      <td>0.949204</td>\n",
       "      <td>stealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1045</td>\n",
       "      <td>0.948662</td>\n",
       "      <td>sleeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42040</td>\n",
       "      <td>0.948421</td>\n",
       "      <td>equalizer 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5363</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>our man flint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44339</td>\n",
       "      <td>0.946519</td>\n",
       "      <td>the underground world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28148</td>\n",
       "      <td>0.946031</td>\n",
       "      <td>speed cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29872</td>\n",
       "      <td>0.945153</td>\n",
       "      <td>angels die hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26340</td>\n",
       "      <td>0.944840</td>\n",
       "      <td>the siege of firebase gloria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25184</td>\n",
       "      <td>0.944059</td>\n",
       "      <td>penguins of madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8916</td>\n",
       "      <td>0.943807</td>\n",
       "      <td>killer klowns from outer space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2175</td>\n",
       "      <td>0.942744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30707</td>\n",
       "      <td>0.942183</td>\n",
       "      <td>the nickel ride</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_index  model_score                      title_name\n",
       "0         8603     1.000000                          batman\n",
       "1         5713     0.959517                        rollover\n",
       "2        19227     0.958552                   carbon nation\n",
       "3        43461     0.953251                       megafault\n",
       "4        13835     0.952664                              k2\n",
       "5         6816     0.952464                   death machine\n",
       "6        43165     0.950795            the zookeeper's wife\n",
       "7         7772     0.950565               this island earth\n",
       "8        10227     0.949204                         stealth\n",
       "9         1045     0.948662                         sleeper\n",
       "10       42040     0.948421                  equalizer 2000\n",
       "11        5363     0.946667                   our man flint\n",
       "12       44339     0.946519           the underground world\n",
       "13       28148     0.946031                     speed cross\n",
       "14       29872     0.945153                 angels die hard\n",
       "15       26340     0.944840    the siege of firebase gloria\n",
       "16       25184     0.944059          penguins of madagascar\n",
       "17        8916     0.943807  killer klowns from outer space\n",
       "18        2175     0.942744                             NaN\n",
       "19       30707     0.942183                 the nickel ride"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['title_name'] = output['model_index'].astype(int).map(name_mapper)\n",
    "output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add `original_title`, `keywords`, `tagline` and other metadata to train sample and then retrain embeddings;\n",
    "- Make visualization of embeddings with links of films with each other;\n",
    "- Compare results with the embeddings we created in lecture\n",
    "- Write function get_recommendations() which takes arguments we used 2.3., but such that we can use embeddings of several watched films to get recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we wrap up all pipeline into functions to re-use if needed and it is just prettier to code this way :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making personal rekkos (building get_recommendations() function that will give personal rekkos for each user with filter on watched films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_tags_array(agg_tags: pd.DataFrame,\n",
    "                         text_col = 'overview'):\n",
    "    '''text preprocessing\n",
    "    '''\n",
    "    tags_corpus = agg_tags[text_col].values\n",
    "    tags_corpus = [re.sub('-[!/()0-9]', '', x) for x in tags_corpus]\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "    # preprocess corpus of movie tags before feeding it into Doc2Vec model\n",
    "    tags_doc = [TaggedDocument(words = word_tokenize_clean(D, stop_words), tags = [str(i)]) for i, D in enumerate(tags_corpus)]\n",
    "\n",
    "    return tags_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embeddings(tags_doc: np.array,\n",
    "                     epochs = 20,\n",
    "                     vec_size = 50,\n",
    "                     alpha = .02,\n",
    "                     min_alpha =  0.00025,\n",
    "                     min_count = 5,\n",
    "                     save_path: str = None):\n",
    "    \"\"\"\n",
    "    fit doc2vec model to prepared corpus\n",
    "    :tags_doc: result of get_clean_tags_array()\n",
    "    :max_epocs: int\n",
    "    :vec_size: int\n",
    "    :alpha: float\n",
    "    \"\"\"\n",
    "    #initialize\n",
    "    model = Doc2Vec(vector_size = vec_size,\n",
    "                    alpha = alpha, \n",
    "                    min_alpha = min_alpha,\n",
    "                    min_count = min_count,\n",
    "                    dm = 0)\n",
    "    \n",
    "    #generate vocab from all tag docs\n",
    "    model.build_vocab(tags_doc)\n",
    "    \n",
    "    #train model\n",
    "    model.train(tags_doc,\n",
    "                total_examples = model.corpus_count,\n",
    "                epochs = epochs)\n",
    "    \n",
    "    #save model to dir\n",
    "    if save_path:\n",
    "        model.save(f'{save_path}/d2v_model.pkl')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_doc = get_clean_tags_array(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_embeddings(tags_doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets load interactions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100004, 4) (88299, 4)\n"
     ]
    }
   ],
   "source": [
    "interactions = read_csv_from_gdrive(RATINGS_SMALL_URL)\n",
    "interactions['movieId'] = interactions['movieId'].astype(str)\n",
    "movies_metadata.rename(columns = {'id': 'movieId'}, inplace = True)\n",
    "interactions_filtered = interactions.loc[interactions['movieId'].isin(sample['model_index'])]\n",
    "print(interactions.shape, interactions_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create users input\n",
    "users = interactions_filtered[['userId']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>watched_movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[31, 1029, 1061, 1129, 1172, 1263, 1287, 1293,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[10, 17, 39, 47, 50, 52, 62, 110, 144, 150, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[60, 110, 247, 267, 296, 318, 355, 356, 377, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[10, 34, 112, 141, 153, 173, 185, 260, 289, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 39, 104, 141, 150, 231, 277, 344, 356, 364...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                     watched_movies\n",
       "0       1  [31, 1029, 1061, 1129, 1172, 1263, 1287, 1293,...\n",
       "1       2  [10, 17, 39, 47, 50, 52, 62, 110, 144, 150, 15...\n",
       "2       3  [60, 110, 247, 267, 296, 318, 355, 356, 377, 5...\n",
       "3       4  [10, 34, 112, 141, 153, 173, 185, 260, 289, 29...\n",
       "4       5  [3, 39, 104, 141, 150, 231, 277, 344, 356, 364..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_items = interactions_filtered.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "users['watched_movies'] = users['userId'].map(known_items)\n",
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_vectors = model.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to get the embeddings of a list of movies\n",
    "def get_movie_embeddings(movie_list):\n",
    "    embeddings = [movie_vectors[int(movie_id)] for movie_id in movie_list]\n",
    "    # Remove None values\n",
    "    embeddings = [x for x in embeddings if x is not None]\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "users['watched_movies_embeddings'] = users['watched_movies'].apply(get_movie_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>watched_movies</th>\n",
       "      <th>watched_movies_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[31, 1029, 1061, 1129, 1172, 1263, 1287, 1293,...</td>\n",
       "      <td>[[0.03041095, -0.096139565, 0.124947004, 0.037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[10, 17, 39, 47, 50, 52, 62, 110, 144, 150, 15...</td>\n",
       "      <td>[[-0.15852125, -0.28294635, 0.26542282, -0.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[60, 110, 247, 267, 296, 318, 355, 356, 377, 5...</td>\n",
       "      <td>[[-0.07212124, -0.043663364, 0.28096688, 0.014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[10, 34, 112, 141, 153, 173, 185, 260, 289, 29...</td>\n",
       "      <td>[[-0.15852125, -0.28294635, 0.26542282, -0.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 39, 104, 141, 150, 231, 277, 344, 356, 364...</td>\n",
       "      <td>[[-0.05128915, -0.05324564, 0.34414858, -0.062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                     watched_movies  \\\n",
       "0       1  [31, 1029, 1061, 1129, 1172, 1263, 1287, 1293,...   \n",
       "1       2  [10, 17, 39, 47, 50, 52, 62, 110, 144, 150, 15...   \n",
       "2       3  [60, 110, 247, 267, 296, 318, 355, 356, 377, 5...   \n",
       "3       4  [10, 34, 112, 141, 153, 173, 185, 260, 289, 29...   \n",
       "4       5  [3, 39, 104, 141, 150, 231, 277, 344, 356, 364...   \n",
       "\n",
       "                           watched_movies_embeddings  \n",
       "0  [[0.03041095, -0.096139565, 0.124947004, 0.037...  \n",
       "1  [[-0.15852125, -0.28294635, 0.26542282, -0.050...  \n",
       "2  [[-0.07212124, -0.043663364, 0.28096688, 0.014...  \n",
       "3  [[-0.15852125, -0.28294635, 0.26542282, -0.050...  \n",
       "4  [[-0.05128915, -0.05324564, 0.34414858, -0.062...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets calculate mean embeddings for each user:\n",
    "\n",
    "mean_embeddings = []\n",
    "for embedding_list in users['watched_movies_embeddings']:\n",
    "    embeddings = np.array(embedding_list)\n",
    "    # Take the mean of the embeddings for movies that the user has watched\n",
    "    user_embedding = np.mean(embeddings, axis=0)\n",
    "    mean_embeddings.append(user_embedding)\n",
    "    \n",
    "# Add the mean_embeddings column to dataframe\n",
    "users['mean_embeddings'] = mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping titles and ids for furher function\n",
    "name_mapper = dict(zip(sample['model_index'], sample['original_title']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that creates recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rekkos(data: pd.DataFrame, number_of_samples: int):\n",
    "    similars = model.docvecs.most_similar(positive=data, topn = number_of_samples)\n",
    "    return [name_mapper.get(movie_id[0], movie_id[0]) for movie_id in similars]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate maximum films that we should predict to recommend every user fresh films:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_max = []\n",
    "for row in users.index:\n",
    "    lst_max.append(len(users['watched_movies'][row]))\n",
    "\n",
    "max_films = max(lst_max)+20\n",
    "max_films\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watched_films_filter(df: pd.DataFrame, number_of_samples: int):\n",
    "    \"\"\"\n",
    "    calculates mean rating to define popular titles with taking to the account watched films\n",
    "    \"\"\"\n",
    "    popular_titles = df['rekkos']\n",
    "    personal_rekkos = {}\n",
    "    for key in known_items.keys():\n",
    "        popular_titles = df['rekkos'][key-1]\n",
    "        list_of_unknown_films = [x for x in popular_titles if x not in known_items[key]]\n",
    "        personal_rekkos[key] = list(list_of_unknown_films[:number_of_samples])\n",
    "    return personal_rekkos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendatios(data: pd.DataFrame, \n",
    "                       number_of_samples: int,\n",
    "                       item_column: str):\n",
    "    \n",
    "    '''function that returns dataframe with recommended films for each user based on their previous history of watches.\n",
    "    :data : pd.DataFrame \n",
    "    :number_of_samples : number of films needed to be predicted,\n",
    "    :item_column : column with watched films in df.\n",
    "    '''\n",
    "\n",
    "    # creating embeddings for each movie\n",
    "    data['watched_movies_embeddings'] = data[item_column].apply(get_movie_embeddings)\n",
    "\n",
    "    #counting mean embeddings for watched_films\n",
    "    mean_embeddings = []\n",
    "    for embedding_list in data['watched_movies_embeddings']:\n",
    "        embeddings = np.array(embedding_list)\n",
    "        # Take the mean of the embeddings for movies that the user has watched\n",
    "        user_embedding = np.mean(embeddings, axis=0)\n",
    "        mean_embeddings.append(user_embedding)\n",
    "    \n",
    "    # Adding the mean_embeddings column to dataframe\n",
    "    data['mean_embeddings'] = mean_embeddings\n",
    "\n",
    "    #receiving rekkos\n",
    "    data['rekkos'] = data['mean_embeddings'].apply(rekkos, number_of_samples=max_films)\n",
    "\n",
    "    #filtering watched films \n",
    "    personal_rekkos = watched_films_filter(data, number_of_samples=number_of_samples)\n",
    "    data['rekkos'] = data['userId'].map(personal_rekkos)\n",
    "    \n",
    "    return data[['userId', 'rekkos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rekkos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Elle boit pas, elle fume pas, elle drague pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Uncle Nick, Happy Burnout, Columbus Day, Whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Uncle Nick, The Southerner, Happy Burnout, Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Fantozzi Contro Tutti, Vääpeli Körmy ja marsa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Vääpeli Körmy ja marsalkan sauva, Inside, The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                             rekkos\n",
       "0       1  [Elle boit pas, elle fume pas, elle drague pas...\n",
       "1       2  [Uncle Nick, Happy Burnout, Columbus Day, Whit...\n",
       "2       3  [Uncle Nick, The Southerner, Happy Burnout, Bu...\n",
       "3       4  [Fantozzi Contro Tutti, Vääpeli Körmy ja marsa...\n",
       "4       5  [Vääpeli Körmy ja marsalkan sauva, Inside, The..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_df = get_recommendatios(data= users,number_of_samples= 20, item_column='watched_movies')\n",
    "recommended_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features into the model (this model works worse that first one, that is why I used first in recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  45466 non-null  object \n",
      " 1   belongs_to_collection  4494 non-null   object \n",
      " 2   budget                 45466 non-null  object \n",
      " 3   genres                 45466 non-null  object \n",
      " 4   homepage               7782 non-null   object \n",
      " 5   movieId                45466 non-null  object \n",
      " 6   imdb_id                45449 non-null  object \n",
      " 7   original_language      45455 non-null  object \n",
      " 8   original_title         45466 non-null  object \n",
      " 9   overview               44512 non-null  object \n",
      " 10  popularity             45461 non-null  object \n",
      " 11  poster_path            45080 non-null  object \n",
      " 12  production_companies   45463 non-null  object \n",
      " 13  production_countries   45463 non-null  object \n",
      " 14  release_date           45379 non-null  object \n",
      " 15  revenue                45460 non-null  float64\n",
      " 16  runtime                45203 non-null  float64\n",
      " 17  spoken_languages       45460 non-null  object \n",
      " 18  status                 45379 non-null  object \n",
      " 19  tagline                20412 non-null  object \n",
      " 20  title                  45460 non-null  object \n",
      " 21  video                  45460 non-null  object \n",
      " 22  vote_average           45460 non-null  float64\n",
      " 23  vote_count             45460 non-null  float64\n",
      "dtypes: float64(4), object(20)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "movies_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = movies_metadata[['movieId', 'original_title', 'overview', 'genres', 'tagline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   movieId         45466 non-null  object\n",
      " 1   original_title  45466 non-null  object\n",
      " 2   overview        44512 non-null  object\n",
      " 3   genres          45466 non-null  object\n",
      " 4   tagline         20412 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "new_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.loc[new_sample['overview'].isnull(), 'overview'] = new_sample.loc[new_sample['overview'].isnull(), 'original_title']\n",
    "new_sample['tagline'] = new_sample['tagline'].fillna(new_sample['original_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   movieId         45466 non-null  object\n",
      " 1   original_title  45466 non-null  object\n",
      " 2   overview        45466 non-null  object\n",
      " 3   genres          45466 non-null  object\n",
      " 4   tagline         45466 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "new_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   model_index     45466 non-null  object\n",
      " 1   movieId         45466 non-null  object\n",
      " 2   original_title  45466 non-null  object\n",
      " 3   overview        45466 non-null  object\n",
      " 4   genres          45466 non-null  object\n",
      " 5   tagline         45466 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "new_sample = new_sample.reset_index().rename(columns = {'index': 'model_index'})\n",
    "new_sample['model_index'] = new_sample['model_index'].astype(str)\n",
    "new_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_inv_mapper = dict(zip(new_sample['original_title'].str.lower(), new_sample['model_index'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_tags_array(agg_tags: pd.DataFrame,\n",
    "                         text_cols = ['overview', 'original_title', 'tagline']):\n",
    "    '''text preprocessing\n",
    "    '''\n",
    "    # concatenate the text from all columns of interest\n",
    "    tags_corpus = agg_tags[text_cols].apply(lambda x: ' '.join(x), axis=1).values\n",
    "    \n",
    "    # preprocess the text\n",
    "    tags_corpus = [re.sub('-[!/()0-9]', '', x) for x in tags_corpus]\n",
    "    stop_words = stopwords.words('english')\n",
    "    tags_doc = [TaggedDocument(words = word_tokenize_clean(D, stop_words), tags = [str(i)]) for i, D in enumerate(tags_corpus)]\n",
    "\n",
    "    return tags_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_array = get_clean_tags_array(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embeddings(tags_doc: np.array,\n",
    "                     epochs = 20,\n",
    "                     vec_size = 50,\n",
    "                     alpha = .02,\n",
    "                     min_alpha =  0.00025,\n",
    "                     min_count = 5,\n",
    "                     save_path: str = None):\n",
    "    \"\"\"\n",
    "    fit doc2vec model to prepared corpus\n",
    "    :tags_doc: result of get_clean_tags_array()\n",
    "    :max_epocs: int\n",
    "    :vec_size: int\n",
    "    :alpha: float\n",
    "    \"\"\"\n",
    "    #initialize\n",
    "    model = Doc2Vec(vector_size = vec_size,\n",
    "                    alpha = alpha, \n",
    "                    min_alpha = min_alpha,\n",
    "                    min_count = min_count,\n",
    "                    dm = 0)\n",
    "    \n",
    "    #generate vocab from all tag docs\n",
    "    model.build_vocab(tags_doc)\n",
    "    \n",
    "    #train model\n",
    "    model.train(tags_doc,\n",
    "                total_examples = model.corpus_count,\n",
    "                epochs = epochs)\n",
    "    \n",
    "    #save model to dir\n",
    "    if save_path:\n",
    "        model.save(f'{save_path}/d2v_model.pkl')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_embeddings(tags_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8603"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id = movies_inv_mapper['batman']\n",
    "movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_vectors = model.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings = movies_vectors[movie_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.0160208e-02, -1.8253161e-01,  2.7860367e-01, -1.9340388e-02,\n",
       "       -2.6517289e-02,  1.8640238e-01, -3.3289498e-01, -6.1052497e-02,\n",
       "       -3.5598734e-01, -3.8000790e-04, -1.7075939e-01, -1.1591378e-01,\n",
       "        7.9556266e-05, -2.0348647e-01,  2.0137224e-01, -9.6725069e-02,\n",
       "        2.0268382e-01, -1.6914688e-01,  1.5876643e-01, -2.0017324e-01,\n",
       "        9.4643004e-02,  1.4631657e-01, -3.1319104e-02,  1.7299244e-01,\n",
       "        1.5535557e-01,  2.1169420e-01, -1.1648132e-01, -1.2777744e-01,\n",
       "        3.0593607e-01, -2.5232095e-01,  2.5669878e-02,  6.3207977e-02,\n",
       "       -4.3362007e-02,  7.3174194e-02, -3.5317650e-01,  2.9851297e-01,\n",
       "       -1.5897123e-02, -7.3791169e-02,  1.8562043e-01,  2.0299160e-01,\n",
       "        1.6092224e-01, -2.9811222e-02, -3.5844274e-02,  1.4017850e-01,\n",
       "        1.3455860e-02, -3.6246192e-01,  6.1877277e-02,  2.6866566e-02,\n",
       "       -1.2715700e-01,  4.0484986e-01], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_index</th>\n",
       "      <th>model_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4276</td>\n",
       "      <td>0.930426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10406</td>\n",
       "      <td>0.918615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33808</td>\n",
       "      <td>0.917352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11186</td>\n",
       "      <td>0.917191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36296</td>\n",
       "      <td>0.915977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_index  model_score\n",
       "0        4276     0.930426\n",
       "1       10406     0.918615\n",
       "2       33808     0.917352\n",
       "3       11186     0.917191\n",
       "4       36296     0.915977"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similars = model.docvecs.most_similar(positive=[movie_embeddings], topn=20)\n",
    "output = pd.DataFrame(similars, columns = ['model_index', 'model_score'])\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_index</th>\n",
       "      <th>model_score</th>\n",
       "      <th>title_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34282</td>\n",
       "      <td>0.915982</td>\n",
       "      <td>kshanbhar vishranti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32667</td>\n",
       "      <td>0.912129</td>\n",
       "      <td>some voices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13779</td>\n",
       "      <td>0.910338</td>\n",
       "      <td>imagine that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24762</td>\n",
       "      <td>0.908032</td>\n",
       "      <td>the returned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45022</td>\n",
       "      <td>0.907549</td>\n",
       "      <td>ماجرای نیمروز</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22855</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>dug's special mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34199</td>\n",
       "      <td>0.906633</td>\n",
       "      <td>der rest ist schweigen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34896</td>\n",
       "      <td>0.906432</td>\n",
       "      <td>recep i̇vedik 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19771</td>\n",
       "      <td>0.905578</td>\n",
       "      <td>stolen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43461</td>\n",
       "      <td>0.905525</td>\n",
       "      <td>megafault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41008</td>\n",
       "      <td>0.905198</td>\n",
       "      <td>el custodio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31064</td>\n",
       "      <td>0.905110</td>\n",
       "      <td>da geht noch was!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26857</td>\n",
       "      <td>0.904694</td>\n",
       "      <td>snow in august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42357</td>\n",
       "      <td>0.903511</td>\n",
       "      <td>猫の集会</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15738</td>\n",
       "      <td>0.903337</td>\n",
       "      <td>tarzan's magic fountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27532</td>\n",
       "      <td>0.903010</td>\n",
       "      <td>en blomst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16095</td>\n",
       "      <td>0.902996</td>\n",
       "      <td>ten skies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27652</td>\n",
       "      <td>0.902879</td>\n",
       "      <td>hyvä poika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23886</td>\n",
       "      <td>0.902736</td>\n",
       "      <td>rituals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33282</td>\n",
       "      <td>0.902635</td>\n",
       "      <td>chilling visions: 5 senses of fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_index  model_score                          title_name\n",
       "0        34282     0.915982                 kshanbhar vishranti\n",
       "1        32667     0.912129                         some voices\n",
       "2        13779     0.910338                        imagine that\n",
       "3        24762     0.908032                        the returned\n",
       "4        45022     0.907549                       ماجرای نیمروز\n",
       "5        22855     0.906911               dug's special mission\n",
       "6        34199     0.906633              der rest ist schweigen\n",
       "7        34896     0.906432                     recep i̇vedik 2\n",
       "8        19771     0.905578                              stolen\n",
       "9        43461     0.905525                           megafault\n",
       "10       41008     0.905198                         el custodio\n",
       "11       31064     0.905110                   da geht noch was!\n",
       "12       26857     0.904694                      snow in august\n",
       "13       42357     0.903511                                猫の集会\n",
       "14       15738     0.903337             tarzan's magic fountain\n",
       "15       27532     0.903010                           en blomst\n",
       "16       16095     0.902996                           ten skies\n",
       "17       27652     0.902879                          hyvä poika\n",
       "18       23886     0.902736                             rituals\n",
       "19       33282     0.902635  chilling visions: 5 senses of fear"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['title_name'] = output['model_index'].astype(int).map(name_mapper)\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, model with more attributes works worse, it doesn't have even batman by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import umap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8f224ef5b38d3f37bfed6caef0c716d4d91a2a669669a54b1ef3cb1369b8b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
